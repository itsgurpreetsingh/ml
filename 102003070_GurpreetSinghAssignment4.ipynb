{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zCv2wzgZz15c"
      },
      "outputs": [],
      "source": [
        "#Question1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9VU8BPuz2g3"
      },
      "outputs": [],
      "source": [
        "x = np.array([i*np.pi/180 for i in range(60,300,4)])\n",
        "np.random.seed(10)\n",
        "y = np.sin(x) + np.random.normal(0,0.15,len(x))\n",
        "df= pd.DataFrame(np.column_stack([x,y]),columns=['x','y'])\n",
        "for i in range(2,16):\n",
        "  colname = 'x_%d'%i\n",
        "  df[colname] = df['x']**i\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "peueu2EM0GJ4"
      },
      "outputs": [],
      "source": [
        "X=df.drop(['y'],axis=1)\n",
        "Y=df.iloc[:,1]\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "X_scaled=scaler.fit_transform(X)\n",
        "X_scaled=np.insert(X_scaled,0,values=1,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9lOXNG1V0JHM"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.3, random_state=42)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcM97IgY0KL9"
      },
      "outputs": [],
      "source": [
        "betas=[]\n",
        "l_rate = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
        "r_para = [pow(10,-15), pow(10,-10), pow(10,-5), pow(10,-3), 0, 1, 10, 20]\n",
        "for learning_rate in l_rate:\n",
        "  for r_p in r_para:\n",
        "    beta = np.zeros(X_train.shape[1]) ##+1\n",
        "    for j in range(X_train.shape[1]):\n",
        "      parsum=0\n",
        "      for i in range(X_train.shape[0]):\n",
        "        sum=0\n",
        "        sum+=beta[0]\n",
        "        for k in range(X_train.shape[1]):\n",
        "          if k==0:\n",
        "            continue\n",
        "          sum+=beta[k]*X_train[i][k]\n",
        "          ## \n",
        "        sum=sum-Y_train[i]   ## what is size of y_train\n",
        "        sum=sum*X_train[i][j]\n",
        "        ## i loop ends\n",
        "      parsum=sum\n",
        "      one=(parsum*learning_rate)/X_train.shape[0]   ## formula used \n",
        "      two=1-((learning_rate*r_p)/X_train.shape[0])\n",
        "      beta[j]=(beta[j]*two)-one\n",
        "      ## lamda loop ends\n",
        "    betas.append(beta)\n",
        "    ## learning rate loop ends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "QhmyOgTE0OSt"
      },
      "outputs": [],
      "source": [
        "r2 = []\n",
        "from sklearn.metrics import r2_score\n",
        "for beta in betas:\n",
        "  Y_pred_val = X_val.dot(beta)\n",
        "  r2.append(r2_score(Y_val, Y_pred_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LyepYwm0Rjk"
      },
      "outputs": [],
      "source": [
        "betas=[]\n",
        "l_rate=[0.0001,0.001,0.01,0.1,1,10]\n",
        "r_para=[pow(10,-15),pow(10,-10),pow(10,-5),pow(10,-3),0,1,10,20]\n",
        "for learning_rate in l_rate:\n",
        "  for r_p in r_para:\n",
        "    beta=np.zeros(X_train.shape[1])\n",
        "    for j in range(X_train.shape[1]):\n",
        "      parsum=0\n",
        "      for i in range(X_train.shape[0]):\n",
        "        sum=0\n",
        "        for k in range(X_train.shape[1]):\n",
        "          sum+=beta[k]*X_train[i][k]\n",
        "        sum-=Y_train[i]\n",
        "        sum*=X_train[i][j]\n",
        "      parsum=sum\n",
        "      one=(parsum*learning_rate)/X_train.shape[0]\n",
        "      two=1-((learning_rate*r_p)/Y_train.shape[0])\n",
        "      beta[j]=(beta[j]*two)-one\n",
        "    betas.append(beta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frYqgodK1Cto"
      },
      "source": [
        "Question 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7rHJhJfu1HUJ",
        "outputId": "7b5235d8-8834-4188-989d-9ab876030841"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(263, 20)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df=pd.read_csv(\"/content/ThisIsTheFile.csv\")\n",
        "df.shape\n",
        "df1=df.dropna()\n",
        "df1.shape\n",
        "df2=pd.get_dummies(df1,columns=['League','Division','NewLeague'],drop_first=True)\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "clf = LocalOutlierFactor(n_neighbors = 20, contamination = 0.05)\n",
        "clf.fit_predict(df2)\n",
        "dff_scores = clf.negative_outlier_factor_\n",
        "import seaborn as sns\n",
        "sns.boxplot(x=dff_scores);\n",
        "df2.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX7H6FtsLQqL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "fmmHcphh2MSK",
        "outputId": "0492bf8d-57ee-4689-a997-603349c2ccd9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-92ef3118-e327-4336-91f1-c3d01fe4cd05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AtBat</th>\n",
              "      <th>Hits</th>\n",
              "      <th>HmRun</th>\n",
              "      <th>Runs</th>\n",
              "      <th>RBI</th>\n",
              "      <th>Walks</th>\n",
              "      <th>Years</th>\n",
              "      <th>CAtBat</th>\n",
              "      <th>CHits</th>\n",
              "      <th>CHmRun</th>\n",
              "      <th>CRuns</th>\n",
              "      <th>CRBI</th>\n",
              "      <th>CWalks</th>\n",
              "      <th>PutOuts</th>\n",
              "      <th>Assists</th>\n",
              "      <th>Errors</th>\n",
              "      <th>Salary</th>\n",
              "      <th>League_N</th>\n",
              "      <th>Division_W</th>\n",
              "      <th>NewLeague_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.045215</td>\n",
              "      <td>0.042742</td>\n",
              "      <td>0.029686</td>\n",
              "      <td>0.024506</td>\n",
              "      <td>0.040677</td>\n",
              "      <td>0.051741</td>\n",
              "      <td>0.098795</td>\n",
              "      <td>0.060712</td>\n",
              "      <td>0.053103</td>\n",
              "      <td>0.039633</td>\n",
              "      <td>0.040424</td>\n",
              "      <td>0.055269</td>\n",
              "      <td>0.062428</td>\n",
              "      <td>0.096651</td>\n",
              "      <td>0.014158</td>\n",
              "      <td>0.056929</td>\n",
              "      <td>0.041845</td>\n",
              "      <td>0.089803</td>\n",
              "      <td>0.086387</td>\n",
              "      <td>0.090536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.068755</td>\n",
              "      <td>0.068598</td>\n",
              "      <td>0.076336</td>\n",
              "      <td>0.067392</td>\n",
              "      <td>0.077073</td>\n",
              "      <td>0.100829</td>\n",
              "      <td>0.021170</td>\n",
              "      <td>0.028587</td>\n",
              "      <td>0.029063</td>\n",
              "      <td>0.036186</td>\n",
              "      <td>0.028209</td>\n",
              "      <td>0.035511</td>\n",
              "      <td>0.043783</td>\n",
              "      <td>0.134578</td>\n",
              "      <td>0.026999</td>\n",
              "      <td>0.079700</td>\n",
              "      <td>0.042285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086387</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.071196</td>\n",
              "      <td>0.074402</td>\n",
              "      <td>0.084817</td>\n",
              "      <td>0.066371</td>\n",
              "      <td>0.083495</td>\n",
              "      <td>0.049088</td>\n",
              "      <td>0.077625</td>\n",
              "      <td>0.099068</td>\n",
              "      <td>0.100164</td>\n",
              "      <td>0.129237</td>\n",
              "      <td>0.104272</td>\n",
              "      <td>0.111873</td>\n",
              "      <td>0.058932</td>\n",
              "      <td>0.030586</td>\n",
              "      <td>0.003622</td>\n",
              "      <td>0.017079</td>\n",
              "      <td>0.044047</td>\n",
              "      <td>0.089803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.046076</td>\n",
              "      <td>0.045908</td>\n",
              "      <td>0.042409</td>\n",
              "      <td>0.039822</td>\n",
              "      <td>0.044959</td>\n",
              "      <td>0.039801</td>\n",
              "      <td>0.014114</td>\n",
              "      <td>0.006971</td>\n",
              "      <td>0.006423</td>\n",
              "      <td>0.006893</td>\n",
              "      <td>0.006045</td>\n",
              "      <td>0.006141</td>\n",
              "      <td>0.005494</td>\n",
              "      <td>0.123108</td>\n",
              "      <td>0.013170</td>\n",
              "      <td>0.022771</td>\n",
              "      <td>0.008061</td>\n",
              "      <td>0.089803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.085263</td>\n",
              "      <td>0.089177</td>\n",
              "      <td>0.016963</td>\n",
              "      <td>0.075561</td>\n",
              "      <td>0.054593</td>\n",
              "      <td>0.046434</td>\n",
              "      <td>0.077625</td>\n",
              "      <td>0.077593</td>\n",
              "      <td>0.072054</td>\n",
              "      <td>0.010913</td>\n",
              "      <td>0.063092</td>\n",
              "      <td>0.044856</td>\n",
              "      <td>0.032296</td>\n",
              "      <td>0.043126</td>\n",
              "      <td>0.138619</td>\n",
              "      <td>0.142321</td>\n",
              "      <td>0.066070</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086387</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.071339</td>\n",
              "      <td>0.067015</td>\n",
              "      <td>0.029686</td>\n",
              "      <td>0.066371</td>\n",
              "      <td>0.051382</td>\n",
              "      <td>0.049088</td>\n",
              "      <td>0.035284</td>\n",
              "      <td>0.047580</td>\n",
              "      <td>0.051259</td>\n",
              "      <td>0.018380</td>\n",
              "      <td>0.047728</td>\n",
              "      <td>0.041518</td>\n",
              "      <td>0.022973</td>\n",
              "      <td>0.049702</td>\n",
              "      <td>0.002963</td>\n",
              "      <td>0.017079</td>\n",
              "      <td>0.061666</td>\n",
              "      <td>0.089803</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0.070622</td>\n",
              "      <td>0.071764</td>\n",
              "      <td>0.021204</td>\n",
              "      <td>0.077603</td>\n",
              "      <td>0.053523</td>\n",
              "      <td>0.124709</td>\n",
              "      <td>0.084682</td>\n",
              "      <td>0.097009</td>\n",
              "      <td>0.096094</td>\n",
              "      <td>0.022401</td>\n",
              "      <td>0.112961</td>\n",
              "      <td>0.060208</td>\n",
              "      <td>0.145665</td>\n",
              "      <td>0.047867</td>\n",
              "      <td>0.125448</td>\n",
              "      <td>0.113857</td>\n",
              "      <td>0.077082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>0.068181</td>\n",
              "      <td>0.066487</td>\n",
              "      <td>0.012723</td>\n",
              "      <td>0.062286</td>\n",
              "      <td>0.046029</td>\n",
              "      <td>0.068988</td>\n",
              "      <td>0.042341</td>\n",
              "      <td>0.029925</td>\n",
              "      <td>0.027537</td>\n",
              "      <td>0.004021</td>\n",
              "      <td>0.027327</td>\n",
              "      <td>0.012415</td>\n",
              "      <td>0.024305</td>\n",
              "      <td>0.005658</td>\n",
              "      <td>0.037206</td>\n",
              "      <td>0.039850</td>\n",
              "      <td>0.033916</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086387</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>0.082248</td>\n",
              "      <td>0.075985</td>\n",
              "      <td>0.038168</td>\n",
              "      <td>0.086793</td>\n",
              "      <td>0.064227</td>\n",
              "      <td>0.103482</td>\n",
              "      <td>0.056454</td>\n",
              "      <td>0.056294</td>\n",
              "      <td>0.054502</td>\n",
              "      <td>0.055715</td>\n",
              "      <td>0.059188</td>\n",
              "      <td>0.056070</td>\n",
              "      <td>0.055269</td>\n",
              "      <td>0.200949</td>\n",
              "      <td>0.043133</td>\n",
              "      <td>0.068314</td>\n",
              "      <td>0.084570</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>0.090574</td>\n",
              "      <td>0.089705</td>\n",
              "      <td>0.038168</td>\n",
              "      <td>0.078624</td>\n",
              "      <td>0.047100</td>\n",
              "      <td>0.041127</td>\n",
              "      <td>0.077625</td>\n",
              "      <td>0.086394</td>\n",
              "      <td>0.092660</td>\n",
              "      <td>0.017232</td>\n",
              "      <td>0.097598</td>\n",
              "      <td>0.047659</td>\n",
              "      <td>0.041452</td>\n",
              "      <td>0.062395</td>\n",
              "      <td>0.001317</td>\n",
              "      <td>0.017079</td>\n",
              "      <td>0.088094</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086387</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>263 rows Ã— 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92ef3118-e327-4336-91f1-c3d01fe4cd05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92ef3118-e327-4336-91f1-c3d01fe4cd05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92ef3118-e327-4336-91f1-c3d01fe4cd05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        AtBat      Hits     HmRun      Runs       RBI     Walks     Years  \\\n",
              "0    0.045215  0.042742  0.029686  0.024506  0.040677  0.051741  0.098795   \n",
              "1    0.068755  0.068598  0.076336  0.067392  0.077073  0.100829  0.021170   \n",
              "2    0.071196  0.074402  0.084817  0.066371  0.083495  0.049088  0.077625   \n",
              "3    0.046076  0.045908  0.042409  0.039822  0.044959  0.039801  0.014114   \n",
              "4    0.085263  0.089177  0.016963  0.075561  0.054593  0.046434  0.077625   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "258  0.071339  0.067015  0.029686  0.066371  0.051382  0.049088  0.035284   \n",
              "259  0.070622  0.071764  0.021204  0.077603  0.053523  0.124709  0.084682   \n",
              "260  0.068181  0.066487  0.012723  0.062286  0.046029  0.068988  0.042341   \n",
              "261  0.082248  0.075985  0.038168  0.086793  0.064227  0.103482  0.056454   \n",
              "262  0.090574  0.089705  0.038168  0.078624  0.047100  0.041127  0.077625   \n",
              "\n",
              "       CAtBat     CHits    CHmRun     CRuns      CRBI    CWalks   PutOuts  \\\n",
              "0    0.060712  0.053103  0.039633  0.040424  0.055269  0.062428  0.096651   \n",
              "1    0.028587  0.029063  0.036186  0.028209  0.035511  0.043783  0.134578   \n",
              "2    0.099068  0.100164  0.129237  0.104272  0.111873  0.058932  0.030586   \n",
              "3    0.006971  0.006423  0.006893  0.006045  0.006141  0.005494  0.123108   \n",
              "4    0.077593  0.072054  0.010913  0.063092  0.044856  0.032296  0.043126   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "258  0.047580  0.051259  0.018380  0.047728  0.041518  0.022973  0.049702   \n",
              "259  0.097009  0.096094  0.022401  0.112961  0.060208  0.145665  0.047867   \n",
              "260  0.029925  0.027537  0.004021  0.027327  0.012415  0.024305  0.005658   \n",
              "261  0.056294  0.054502  0.055715  0.059188  0.056070  0.055269  0.200949   \n",
              "262  0.086394  0.092660  0.017232  0.097598  0.047659  0.041452  0.062395   \n",
              "\n",
              "      Assists    Errors    Salary  League_N  Division_W  NewLeague_N  \n",
              "0    0.014158  0.056929  0.041845  0.089803    0.086387     0.090536  \n",
              "1    0.026999  0.079700  0.042285  0.000000    0.086387     0.000000  \n",
              "2    0.003622  0.017079  0.044047  0.089803    0.000000     0.090536  \n",
              "3    0.013170  0.022771  0.008061  0.089803    0.000000     0.090536  \n",
              "4    0.138619  0.142321  0.066070  0.000000    0.086387     0.000000  \n",
              "..        ...       ...       ...       ...         ...          ...  \n",
              "258  0.002963  0.017079  0.061666  0.089803    0.000000     0.090536  \n",
              "259  0.125448  0.113857  0.077082  0.000000    0.000000     0.000000  \n",
              "260  0.037206  0.039850  0.033916  0.000000    0.086387     0.000000  \n",
              "261  0.043133  0.068314  0.084570  0.000000    0.000000     0.000000  \n",
              "262  0.001317  0.017079  0.088094  0.000000    0.086387     0.000000  \n",
              "\n",
              "[263 rows x 20 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "SS=StandardScaler()\n",
        "col=df2.columns\n",
        "df3=SS.fit_transform(df2)\n",
        "df4=pd.DataFrame(df3, columns=col)\n",
        "df4.shape\n",
        "df5=preprocessing.normalize(df2, axis=0)\n",
        "col=df2.columns\n",
        "df6=pd.DataFrame(df5, columns=col)\n",
        "df6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "s7QjHOye2Mu2"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "y=df4[\"Salary\"]\n",
        "X=df4.drop(\"Salary\", axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20,random_state=46)\n",
        "reg_model = LinearRegression()\n",
        "reg_model.fit(X_train, y_train)\n",
        "y_pred=reg_model.predict(X_test)\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "y=df6[\"Salary\"]\n",
        "X=df6.drop(\"Salary\", axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=46)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sipe30u2Mzg",
        "outputId": "ad006876-0472-433b-9c39-234ab9086ad8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.04488385406376052"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ridge_model=Ridge(alpha=0.5748).fit(X_train,y_train)\n",
        "y_pred= ridge_model.predict(X_test)\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso_model = Lasso(alpha=0.5748).fit(X_train, y_train)\n",
        "y_pred=lasso_model.predict(X_test)\n",
        "np.sqrt(mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdeOCCRZ9fBh"
      },
      "source": [
        "Model after ridge regression performs better "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgl-ZIjw9n11"
      },
      "source": [
        "Question 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AbrefT39m3m",
        "outputId": "74c752e0-e0a7-434f-a2fb-adbcb51317e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20640, 8)\n",
            "Ridge: 0.5530421056931834\n",
            "Lasso: 0.20354861807563682\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6061945447229312"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "print(X.shape)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "for Model in [Ridge, Lasso]:\n",
        "    model = Model()\n",
        "    print('%s: %s' % (Model.__name__, cross_val_score(model, X, y).mean()))\n",
        "\n",
        "from sklearn.linear_model import RidgeCV\n",
        "clf = RidgeCV(alphas=[0.001,0.01,1,10])\n",
        "clf.fit(X,y)\n",
        "clf.score(X,y)\n",
        "\n",
        "from sklearn.linear_model import LassoCV\n",
        "clf = LassoCV(alphas=[0.001,0.01,1,10])\n",
        "clf.fit(X,y)\n",
        "clf.score(X,y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
